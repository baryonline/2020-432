---
title: "Instructions for 432 Project 1"
output: 
    github_document:
        toc: true
---

As a substantial part of your course grade, you will complete two Projects this semester. This document describes Project 1. Instructions for Project 2 will appear later in the term.

# Introduction

It is hard to learn statistics (or anything else) passively; concurrent theory and application are essential. Expert clinical researchers and statisticians repeatedly emphasize how important it is that people be able to write well, present clearly, work to solve problems, and show initiative. This project assignment is designed to help you develop your abilities and have a memorable experience. 

In Project 1, you will be analyzing, presenting and discussing a pair of regression models, specifically a linear regression and a logistic regression, describing a data set you identify. 

## Am I working alone, or in a group?

You can choose either to work alone, or with one other person, to complete Project 1.

- At times, we will require you to share drafts of your work with other people in small groups, but the actual data collection, analysis and report-building work is for you (or you and your partner) to do.

## What Makes an Acceptable Data Set?

1. **Shareable with the World**. The data must be available to you, and shared with me and everyone else in the world (without any identifying information) as a well-tidied .csv file on 2019-02-15. If the data is from another source, the source (web or other) must be completely identified to me. Ongoing projects that require anyone's approval to share data are not appropriate for Project 1, but are likely to be appropriate for Project 2. 
    - For Project 1, you may not use any data set that was used in 431, nor may you revisit the data discussed in your 431 project, and you cannot use any data sets used in the teaching materials for 432. You may not use any data set included in [an R package that we are installing](https://github.com/THOMASELOVE/2019-432/blob/master/packages.md) this semester, other than NHANES. 
    - You **are** allowed to use NHANES data in either Project 1 **or** in Project 2, but not in both. If you do use NHANES data for Project 1, you should be combining information from at least three NHANES data sets. If you used NHANES data in your 431 project, you can use NHANES data again this semester, but you must study new outcomes.
    - You are permitted to use BRFSS data, but you are not permitted to use data from SMART BRFSS, since we will be using that regularly in class.

2. **Size**. A **minimum** of 100 complete observations are required on each variable. It is fine if there are some missing values, as well, so long as there are at least 100 rows with complete observations on all variables you intend to use in each model. The **maximum** data set size is 1000 observations, so if you have something larger than that, you'll need to select a subset.

3. **Outcomes**. The columns must include at least one quantitative outcome and one binary categorical outcome. If necessary, the binary outcome can be generated from the quantitative outcome (as an example, your quantitative outcome could be resting heart rate in beats per minute, and your binary outcome could be whether the resting heart rate is below 70 beats per minute.)

4. **Inputs**. You will need at least four regression inputs (predictors) for each of your two models. At least one of the four must be quantitative (a variable is **not** quantitative for this purpose unless it has at least 10 different, ordered, observed values), *and* at least one must be multi-categorical (with at least 3 categories, each containing a minimum of 30 subjects) for each model. Your other inputs can represent binary, multi-categorical or quantitative data. You can examine different candidate predictors for each outcome, or use the same ones in both your linear and logistic regression models. Depending on your sample size, you can study more regression inputs. Specifically, if you have N complete observations in your data set, you are permitted to study up to 4 + (N-100)/100 candidate regression inputs, rounding down.

# Deliverable 1. The Proposal

The proposal is due Friday 2019-02-15 at 2 PM. Submit via [Canvas](https://canvas.case.edu).

Your proposal will include 
    - (a) a `.csv` file of the data you have chosen
    - (b) a R Markdown file containing the information listed below, and 
    - (c) an HTML document which is the unedited result of knitting your Markdown file.

## The Nine Parts of Your Proposal

The nine pieces of information we should find in the Markdown and HTML versions of your proposal are:

1. Complete information on the source of the data: how did you get it, how was it gathered, by whom, in what setting, for what purpose, and using what sampling strategy.
2. Code to load the raw `.csv` file into a tibble, and tidy/clean up the data to be useful for your modeling work. 
3. A listing of the tibble, with all variables correctly imported (via your code) as the types of variables (factor/integer/numeric, etc.) that you need for modeling. Be sure that your listing specifies the number of rows and number of columns in your tidy data set.
4. A description (one or two sentences) of who or what the subjects (rows) are in your data set.
5. A code book, which provides, for each variable in your tibble, the following information:
    + The name of the variable used in your tibble
    + The type of variable (binary, multi-categorical, quantitative)
    + The details for each variable 
        * if a categorical variable, what are the levels, and what % of subjects fall in each category
        * if a quantitative variable, what is the range of the data, and what are the units of measurement
        * if there are missing data, tell us how many observations are missing, and why, if you know why.
6. A sentence or two for each variable (column) providing a description of what the variable measures or describes, in English.
7. A sentence or two telling us what you will use your linear regression model to explain or predict, *followed by* a sentence or several telling us very precisely which (quantitative) variable will serve as your outcome in your linear regression model, and which four (or more) candidate predictors you intend to use for that model.
8. A sentence or two telling us what you will use your logistic regression model to explain or predict, *followed by* a sentence or several telling us very precisely which (binary) variable will serve as your outcome in your logistic regression model, and which four (or more) candidate predictors you intend to use for that model.
9. An affirmation that the data set meets all of the requirements specified here, most especially that the data can be shared freely over the internet, and that there is no protected information of any kind involved. You need to be able to write "I am certain that it is completely appropriate for these data to be shared with anyone, without any conditions. There are no concerns about privacy or security." If you are unsure whether this is true, select a different data set.

### Evaluating the Project 1 Proposal

- Your project will be evaluated on a scale of 0-10, with one point for getting all of the necessary materials (.csv, .Rmd and HTML) in and then one additional point for each of the nine tasks if they are successfully completed. 
- If you receive a grade lower than 10, you will need to redo until you reach 10. Redos are expected within 48 hours of receipt of the redo request.

## The Group Meetings

- On 2019-02-21, you will meet during class time to present your proposal work, and any subsequent work you have completed on your portfolio. This important session will give you the opportunity  to present a piece of your work to some of your colleagues, and get meaningful feedback from them on the decisions you have made. The TAs will run this session, as Dr. Love will be out of town.

- We hope to set aside some time on 2019-03-07 for a follow-up meeting to nail down last questions in groups, but we're not sure we can promise that yet.

# Deliverable 2. The Portfolio

The portfolio of Project 1 Materials is due Friday 2019-03-15 at 2 PM. Yes, that is the Friday of Spring Break. Submit your work via [Canvas](https://canvas.case.edu).

Your final portfolio will include 
    - (a) a `.csv` file of the data, 
    - (b) a R Markdown file containing the 12 pieces of information listed below, and 
    - (c) an HTML document which is the unedited result of knitting your Markdown file.

## The Twelve Parts of your Portfolio

These tasks should absolutely be built up from your proposal, by adding the last three sections to the work you did there. 

- **Tasks 1-9**. The materials from your proposal, after editing, as needed, to reflect what you actually did and clarifying any points of confusion.
- **Task 10**.  A section on your linear regression model. This should include all relevant code used to prepare your final results. We should be easily capable of finding:
    + Your approach to capturing potential non-linearity. What did the Spearman rho-squared plot suggest, and how did you spend your degrees of freedom?
    + Your variable selection process in developing the model, which should be more than just a stepwise approach. Why did you select the predictors you did? 
    + Your calibration and validation results. What is an appropriate estimate of the likely performance of this model for new data, according to a validated R-squared statistic?
    + An appropriate summary of the final model you landed on, including a listing of the equation, a description of the effect sizes, and an annotated nomogram with a demonstration of a prediction (and appropriate prediction interval) for a new subject of interest.
    + Be sure to read and heed the section 10 advice below. 
- **Task 11**. A section on your logistic regression model.
    + Your approach to capturing potential non-linearity. What did the Spearman rho-squared plot suggest, and how did you spend your degrees of freedom?
    + Your variable selection process in developing the model, which can be a stepwise approach here. Why did you select the predictors you did? 
    + Your calibration and validation results. What is an appropriate estimate of the likely performance of this model for new data, according to a validated C statistic?
    + An appropriate summary of the final model you landed on, including a listing of the equation, a description of the effect sizes, and an annotated nomogram with a demonstration of a predicted probability of having the outcome of interest for a new subject.
    + Be sure to read and heed the section 11 advice below.
- **Task 12**. A 100-250 word discussion of your thoughts on the process. 
    + What was substantially harder or easier than you expected? 
    + What do you wish you'd known at the start of this process that you know now?
    + What was the most confusing part of doing the project?
    + What was the most useful thing you learned while doing the project?

### Final Portfolio Evaluation

To receive a B ... 

0. Meet all submission requirements, on time, with code that works seamlessly with the data you provide.
1. Complete all of the elements from the proposal (tasks 1-9)
2. Present a curated but detailed, appropriate set of linear regression analyses that leads, inexorably, to the selection of a "best choice" model for your data. See the advice on task 10 below.
3. Present a curated but detailed, appropriate set of logistic regression analyses that leads, inexorably, to the selection of a "best choice" model for your data. See the advice on task 11 below.
4. Present your conclusions/reflections about (a) the process, (b) your data and (c) your models (task 12), being sure to address (a), (b) and (c) effectively in at least 2-3 sentences apiece.
5. Present attractive and easy-to-understand graphs that stand on their own thanks to good labeling, well-constructed tables whose message is clear, and clear, nicely presented code. 
6. Build and present output that is courteous to the reader, in that it is pleasing to the eye, and in particular doesn't include useless information, like warning messages the reader doesn't need to heed, or long listings of raw data or other overpowering materials. If it takes longer to scroll through your project than the **example I have provided**, you are on the wrong track.
7. Avoid crippling mistakes, incomplete sentences, and clearly inappropriate conclusions.

A project receiving an "A" grade will **not** be longer, rather it will be better, with more concentrated "useful" stuff throughout, and with more evidence of careful decision-making about what goes into each piece to make it as effective as possible. Dazzle us with your very best work. **Clarity** is the ultimate goal. We seek clear thinking, clear code, clear modeling and clear conclusions. 

Our best advice: To write and code clearly and effectively, have someone else read and criticize your work.

## Things to consider in developing linear models for Task 10

Every bit of your output should be commented on in your work. No output without commentary. We envision your final presentation will show no more than 8 of these items in detail. As few as 4-5 might be sufficient. Many of you will wind up running nearly all of these things, some on multiple models, and then choosing from among them wisely in presenting your final analyses. That is the goal. 

Your presentation needs to land on a single, final model, using both statistical and non-statistical considerations to make a decision. Your presentation may need to explore other models, but this should be done as a way of helping us understand the reasons for your final selection, not as a way of impressing us with the amount of effort you've put into the project. We're interested in clarity, and demonstrated understanding of variation, but not volume.

1. A fitted model using `lm` including an assessment of confidence intervals associated with the fitted coefficients, and an overall ANOVA F test.
2. A fitted model using `ols` including an assessment of summary statistics like R-square, adjusted R-square and the root mean squared error.
3. A summary plot of predictor effects with meaningful confidence intervals, appropriately interpreted.
4. A graph (perhaps with a table as well) showing predictions for new observations of interest.
5. A partitioning of your sample into training and test batches, with an effort to assess the quality of predictions in a test sample for several candidate models. This is particularly appropriate in combination with things like the next two items on this list.
6. A "best subsets" set of four graphs used to help justify variable selection decisions, followed by additional work to make a final choice.
7. A Spearman rho-squared plot leading to an analysis incorporating non-linear predictor terms, an assessment of whether those non-linear terms are helpful, and if so, a nomogram to help illustrate the effect of non-linear predictors on your outcome.
8. The use of the lasso approach to identify variables (main effects) which might be productively included in your model.
9. An effort to validate the summary statistics of your model or models, perhaps with a backwards stepwise approach baked in to validate variable selection at the same time, but also perhaps not.
10. An effort to describe how well your model is calibrated, and where predicted values are more or less trustworthy as a result.
11. An assessment of residuals, leverage and influence that helps guide you to meaningful conclusions - and isn't just a list of the biggest outliers for a particular model-data combination.
12. If there are a meaningful number of missing observations in your study, a complete case analysis to avoid problems with missing data, followed by a model fit using multiple imputation appropriately, with a careful judgment as to the impact of missingness on your conclusions about the data. In general, it is likely that imputation will become more important the more missingness is in your data, but it's worth it to find out.
13. If you are sampling from a larger pool of data, an attempt to see if the conclusions you draw hold up in a newly drawn sample, or perhaps if predictions you make appear to be effective in another, different, sample.

## Things to consider in developing logistic models for Task 11

As with linear models, it is **not** a good idea for all of these elements to appear in your final project, and you are likely going to want to limit yourself in Task 11 to a detailed presentation of 4-8 of these. Choose wisely. Repeating the key advice from above ...

Your presentation in Task 11 needs to land on a single, final model, using *both* statistical and non-statistical considerations to make a decision. Your presentation may need to explore other models, but this should be done as a way of helping us understand the reasons for your final selection, not as a way of impressing us with the amount of effort you've put into the project. We're interested in clarity, and demonstrated understanding of variation, but not volume.

1. A fitted model using `glm` including an assessment of confidence intervals associated with the (exponentiated) fitted coefficients.
2. A fitted model using `lrm` including an assessment of summary statistics like Nagelkerke R-square, C and the Brier score, and an overall likelihood ratio test.
3. A summary plot of predictor effects with meaningful confidence intervals, appropriately interpreted.
4. A graph (perhaps with a table as well) showing predictions for new observations of interest.
5. A Spearman rho-square plot leading to an analysis incorporating non-linear predictor terms, an assessment of whether those non-linear terms are helpful, and if so, a nomogram to help illustrate the effect of non-linear predictors on your outcome. 
6. Actually, a nomogram is useful in logistic regression (especially if it describes fitted probabilities) even if you don't include any non-linear predictors.
7. An effort to validate the summary statistics of your model or models, perhaps with a backwards stepwise approach baked in to validate variable selection at the same time, but also perhaps not.
8. An effort to describe how well your model is calibrated, and where predicted values are more or less trustworthy as a result.
9. An assessment of influence that helps guide you to meaningful conclusions - and isn't just a list of the biggest outliers for a particular model-data combination.
10. If there are a meaningful number of missing observations in your study, a complete case analysis to avoid problems with missing data, followed by a model fit using multiple imputation appropriately, with a careful judgment as to the impact of missingness on your conclusions about the data. In general, it is likely that imputation will become more important the more missingness is in your data, but it's worth it to find out.
11. If you are sampling from a larger pool of data, an attempt to see if the conclusions you draw hold up in a newly drawn sample, or perhaps if predictions you make appear to be effective in another, different, sample.
12. If your binary outcome uses an arbitrary cutpoint for an underlying quantitative outcome, a sensitivity analysis addressing the question of what happens to your conclusions if you change cutpoints.

# Additional Comments on "Spending" Degrees of Freedom and Project 1

The number of degrees of freedom that you are "spending" to fit any particular model is related to the sample size of your data, and the number of coefficients you are fitting in that model.  Paying attention to how you are "spending" degrees of freedom is an important part of fitting any prediction model. If you include more regression coefficients in a model than you can reasonably support with the sample size you have, then you will run into all sorts of problems. In addition, if you fit a whole bunch of models, and compare each in terms of how well it fits to the outcome, then you will definitely run into meaningful problems in terms of the model not performing as well in new data as it appears to perform in your current data. 

If you have a model that currently uses 8 degrees of freedom, that means you've spent 8 df to fit it, not that you have exactly 8 df left to spend, or anything like that.

## What to do for Project 1

The # of degrees of freedom that I want you to spend in Project 1 is small. 

- In a linear model, it is, essentially, your sample size divided by 20, but see the details below on what counts as spending degrees of freedom.
- In a logistic model, if your sample size is n, then the number of degrees of freedom you have to spend is, somewhere between n/50 and n/100, and again, see below for details.

## The Choice You Need to Make (in Project 1)

For many people, the choices in fitting models for Project 1 boil down to, in essence, two related issues:

1. Which predictors will we include in our model?
2. What sort of non-linear terms (and how many of them) will we include in our model?

So, what to do about this? I encourage you to follow either of two paths in doing Project 1. (Do A or B, but not both.)

*Choice A.* If you have a large set of predictors to consider and want to use a statistical procedure to identify which variables should be included in your model, use methods like a kitchen sink approach, stepwise regression, best subsets or some combination to identify several different candidate models and then compare their fit using cross-validation, OR

*Choice B.* If you are settled on which predictors you want to use, use the Spearman rho-squared plot to identify candidate variables for non-linear terms, and add 1-3 such non-linear terms to your model, perhaps comparing the results using cross-validation or through validation of regression summaries like R-square or the C statistic. 

- If you're going to use A, then the Spearman rho-squared plot can be fit after you complete step A, to indicate what predictors might be worthy of looking for non-linearity if new data arrived, but I wouldn't fit any non-linear terms.
- If you're going to use B, then I would take your set of predictors as settled and focus on non-linear terms.

It's your choice whether to use A or B. In either case, I would validate the summary statistics (R^2^ and MSE) after fitting the model.

In either case, for a linear regression, decide in advance all of the models you are going to fit to your outcome. 

## The "20:1 Rule" for Linear Regression

Before you fit any of them, I would verify that your modeling process has not spent more degrees of freedom than you can afford to spend, by the **20:1 rule**. That means that you should:

1. count up the number of degrees of freedom that will be used in each model that you fit to your outcome (so if you plan to use best subsets to produce eight different models, then you used all of the degrees of freedom used by each of those eight models or if you fit four different candidate models, each with 4 degrees of freedom used, that's 16.) Call that total number of degrees of freedom P. 
2. Then take your sample size (the number of complete, non-imputed values in your data set used to fit the models) and call that N. 
3. N/P should be at least 20. 
    - If it's not, you need to rethink your modeling plan until it is.
    - With the small sample sizes I've forced on you, this will mean making some tough decisions. 
    - What may push you towards *Choice B* above is that it's less costly in terms of degrees of freedom, because you don't need to count using the Spearman plot as using up degrees of freedom. 
    - If you're cross-validating, maybe you can get away with N/P being as small as 15.

## For Logistic Regression

For a logistic regression, on the other hand, the sample size standards are even higher. There, N/P should really be greater than 100, but I will be OK if yours is as small as 50. 

This will push you to not consider more than 1-2 non-linear terms if you're following *Choice B*, and to fit a fairly small number of predictors (4-8 in most cases) if you're following *Choice A*.

## What Kind of Non-Linear Terms Should I Consider in Project 1?

As for what type of non-linear terms you should consider in Project 1 should you decide to go down that path, look at the Spearman rho-squared plot and identify the 1-3 predictors that are furthest to the right. Don't fit non-linear terms to the rest of your predictors.

- If the (apparently strongest - furthest to the right) predictor is quantitative, you should be thinking first about a restricted cubic spline with 4 knots, maybe 5 if it won't be a problem for your sample size. 
- If the largest rho-square is associated with a binary or a multi-categorical predictor, create an interaction term with the second-largest rho-squared predictor. 
- If you still have degrees of freedom you're willing to spend after this, proceed down to the second largest predictor in terms of rho-squared, and proceed similarly to the third largest after that, if you like, but don't include more than 3 non-linear terms in Project 1, no matter how large your sample is.

# Dr. Love's Final Bits of Important Advice (Emailed 2019-03-08)

As you prepare your project portfolio for 432, due one week from today 2019-03-15, at 2 PM, via Canvas, I want to emphasize three things related to Tasks 10 and 11:

## Thing 1: Description of Effects

A key element of Task 10 and of Task 11 is that you demonstrate your ability to describe the effect sizes identified by your final models. Follow the guidance I provided in the Effect SIzes document discussed in Class 12, or in my comments in the Quiz 1 answer sketch.

- In Task 10, after your final linear model is fit, create a subsection where you will interpret the effect sizes of your model. Here, you should 
    - specify the effect sizes for all elements of your final model numerically (with both a point estimate and a confidence interval), and graphically (with a plot of those effects (probably through plot(summary(yourmodel)), and  
    - write a detailed and correct description of the effect of at least one predictor on your outcome for your linear regression model, providing all necessary elements of such a description, and link this directly to what the plot is telling you. 
    - We prefer you discuss a statistically and scientifically meaningful effect, should one exist.  Pick an effect to describe that is interesting to you.  

- In Task 11, after your final logistic model is fit, create a subsection where you will interpret the effect sizes of your model. Here, you should 
    - specify the effect sizes for all elements of your final model numerically (with both a point estimate and a confidence interval), and graphically (with a plot of those effects (probably through plot(summary(yourmodel)), and 
    - write a detailed and correct description of the effect of at least one predictor on your outcome for your linear regression model, providing all necessary elements of such a description, and link this directly to what the plot is telling you. 
    - We prefer you discuss a statistically and scientifically meaningful effect, should one exist. Pick an effect to describe that is interesting to you.

## Thing 2: Pick Pathway A or Pathway B

In Tasks 10 and 11 (the actual Analyses) I am primarily interested in whether you can successfully complete one of two pathways for each Task. You want to do either Pathway A or Pathway B in your linear model (Task 10), and then you want to do either Pathway A or Pathway B in your logistic model (Task 11). It's 100% OK to do Pathway A in one task, and B in the other, or to do A both times, or B both times. But don't mix A and B within the same modeling Task in this project.

**Pathway A** - feature selection with all linear terms: this involves starting with a larger set of predictors, and pruning the list down, through a combination of automated methods (best subsets, various stepwise approaches) to identify candidate models, and then cross-validation to make a final selection among those models. 

- In this pathway, a Spearman rho-squared plot would be essentially unnecessary - it would only be used to briefly indicate (but not fit) which terms might be most worthy of looking for non-linearity if new data arrived, but without actually fitting any non-linear terms. 
- If you have missing data, you would likely impute with simple imputation to do this selection work, and then use multiple imputation at the end, after a model has been selected, to provide a final set of evaluations, including assessment of residual plots for your linear model and of influential points in your logistic model. 
- Your description of results should focus on the task of (potentially) reducing the set of available predictors to a parsimonious model and then identify the direction and size of the effects of the variables that remain in your final model, after multiple imputation. 
- A nomogram and ggPredict plots would be of some use here, but less so than in Pathway B, because all of your terms would enter the model in a linear way.

**Pathway B** - including non-linear terms without automated feature selection: this involves the pre-selection of a relatively modest model with somewhere between 4 and 8 predictors, all of which you've decided to definitely include in the model, where you're considering spending additional degrees of freedom (as guided by the Spearman rho-squared plot) to incorporate various non-linear terms. 

- If you have missing data, you would likely impute with simple imputation to do the work of incorporating non-linear terms initially and assessing their impact on the model through cross-validated summary statistics and in-sample ANOVA and AIC assessments, then use multiple imputation at the end, after a model and its various non-linear terms has been selected, to provide a final set of evaluations, including assessment of residual plots for your linear model and of influential points in your logistic model.  
- A nomogram and ggPredict plots will be vitally important here to help describe how some of the terms enter the model in a non-linear way.  
- Your description of results should focus on the task of assessing the influence of each predictor (including non-linear tems) in your model, and then identify the direction and size of the effects of the variables that remain in your final model, after multiple imputation. 

## Thing 3: Reminder to Read the rest of these Instructions

- I have provided earlier guidance on things to consider in developing your Tasks 10 and 11, and those ideas still apply. 
- I have previously provided advice on the four questions you should be trying to address in Task 12 (the discussion) and I want to be sure that you address those points. 
- In grading the projects, Tasks 10-12 each play a substantial role, more so than the previously assessed Tasks 1-9.

What I've written in this email is simply meant to clarify what you need to do. I hope this note helps you think about how to focus your analytic work appropriately, and doesn't add to your confusion. If you have any questions, please contact us at `431-help`.

The Canvas submission link for the project portfolio is now open. I look forward to reviewing your work after 2 PM next Friday. Best wishes, and have a nice break.
